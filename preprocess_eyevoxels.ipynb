{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of eye voxel data\n",
    "This notebook cleans the eye voxels through nuisance regression of the confound time series estimated by fMRIprep. Written by C.Baldassano, adjusted by M.Nau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "**Step 1: Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "import os\n",
    "import h5py\n",
    "from sklearn import linear_model\n",
    "from scipy import stats\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Adjust the following paths to accomodate your folder structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set output directory\n",
    "out_path = 'where/should/the/files/be/written/'\n",
    "\n",
    "# set path to your fMRIprep confound regressors\n",
    "path2conf = 'path/to/fmriprep/'\n",
    "\n",
    "# set path to your eye-voxel files ('mask_*.p')\n",
    "path2eyes = 'path/to/functional_files/'\n",
    "participants = natsorted(os.listdir(path2eyes))\n",
    "print(participants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Nuisance regression of confound time series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over subjects\n",
    "for subj_id, sub in enumerate(participants):\n",
    "    print('Processing subject ', sub)\n",
    "\n",
    "    # make output directory if it does not exist\n",
    "    out_subdir = os.path.join(out_path, sub)\n",
    "    if os.path.exists(out_subdir)==False: \n",
    "        os.mkdir(out_subdir)\n",
    "\n",
    "    # find all file\n",
    "    all_eyes = natsorted(glob.glob(path2eyes + sub + '/mask_rsub*.p'))\n",
    "    all_conf = natsorted(glob.glob(path2conf + sub + '/func' + '/*.tsv'))\n",
    "\n",
    "    for run_id, run in enumerate(all_eyes):\n",
    "        print('      Loading ', run)\n",
    "\n",
    "        # load eyeball data from pickle file\n",
    "        with open(run, 'rb') as f:\n",
    "            in_data = pickle.load(f)\n",
    "\n",
    "        # limit analysis to eye voxels\n",
    "        if run_id == 0:\n",
    "            mask = np.logical_not(np.all(in_data==0,3))\n",
    "            print(mask.shape)\n",
    "        in_data = in_data[mask]\n",
    "        n_TRs = in_data.shape; n_TRs = n_TRs[1]\n",
    "        print(np.argwhere(mask == 1).shape)\n",
    "\n",
    "        # load confound parameters\n",
    "        conf = np.genfromtxt(all_conf[run_id], names=True)\n",
    "        reg = np.column_stack((conf['trans_x'],\n",
    "          conf['trans_x_derivative1'],\n",
    "          conf['trans_y'],\n",
    "          conf['trans_y_derivative1'],\n",
    "          conf['trans_z'],\n",
    "          conf['trans_z_derivative1'],\n",
    "          conf['rot_x'],\n",
    "          conf['rot_x_derivative1'],\n",
    "          conf['rot_y'],\n",
    "          conf['rot_y_derivative1'],\n",
    "          conf['rot_z'],\n",
    "          conf['rot_z_derivative1'],\n",
    "          conf['csf'],\n",
    "          conf['white_matter'],\n",
    "          conf['framewise_displacement'], ))\n",
    "\n",
    "        # do the data cleaning\n",
    "        reg = np.nan_to_num(reg)\n",
    "        regr = linear_model.LinearRegression()\n",
    "        regr.fit(reg, in_data.T)\n",
    "        in_data = in_data - np.dot(regr.coef_, reg.T) - regr.intercept_[:, np.newaxis]\n",
    "\n",
    "        # reshape data to 4D\n",
    "        out_data = np.zeros((mask.shape[0],mask.shape[1],mask.shape[2], in_data.shape[1]))\n",
    "        out_data.shape\n",
    "        for i in range(0, in_data.shape[1]):\n",
    "            out_data[mask==True, i] = in_data[:,i]\n",
    "        out_data = out_data.astype('float32')\n",
    "\n",
    "        # define output file names\n",
    "        out_name = run.split('/'); \n",
    "        out_name = 'clean_' + out_name[-1]\n",
    "        out_name = out_name.split('.')\n",
    "\n",
    "        # save pickle file (if preferred over NIFTI)\n",
    "        # out_p   = os.path.join(out_subdir,out_name[0] + '.p')\n",
    "        # print('      writing ', out_p)\n",
    "        # pickle.dump(out_data, open(out_p, 'wb'))\n",
    "\n",
    "        # save nifti file\n",
    "        out_nii = os.path.join(out_subdir,out_name[0] + '.nii')\n",
    "        print('      writing ', out_nii)\n",
    "        out_data = nib.Nifti1Image(out_data, affine=np.eye(4))\n",
    "        nib.save(out_data, out_nii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Crop fMRI data to movie and recall onsets and offsets (specific to the Sherlock Movie Viewing Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropping1 = np.array([[20,7],\n",
    "                      [20,7],\n",
    "                      [20,6],\n",
    "                      [6,13],\n",
    "                      [20,8],\n",
    "                      [20,7],\n",
    "                      [20,6],\n",
    "                      [20,5],\n",
    "                      [20,4],\n",
    "                      [20,6],\n",
    "                      [20,3],\n",
    "                      [20,5],\n",
    "                      [20,5],\n",
    "                      [20,6],\n",
    "                      [20,3],\n",
    "                      [20,5]], dtype=int)\n",
    "\n",
    "cropping2 = np.array([[20,11],\n",
    "                      [20,7],\n",
    "                      [20,7],\n",
    "                      [6,5],\n",
    "                      [20,7],\n",
    "                      [20,7],\n",
    "                      [20,10],\n",
    "                      [20,7],\n",
    "                      [20,8],\n",
    "                      [20,8],\n",
    "                      [20,6],\n",
    "                      [20,7],\n",
    "                      [20,6],\n",
    "                      [20,4],\n",
    "                      [20,4],\n",
    "                      [20,6]], dtype=int)\n",
    "\n",
    "\n",
    "nv = 14236\n",
    "D = np.zeros((1976, 14236, 16))\n",
    "for i in range(16):\n",
    "    print('Loading', i)\n",
    "    m1 = h5py.File('preprocessed/sub-%02d.h5' % (i+1,))['sherlockPart1']['D'][:]\n",
    "    m2 = h5py.File('preprocessed/sub-%02d.h5' % (i+1,))['sherlockPart2']['D'][:]\n",
    "    D[:,:,i] = np.concatenate((m1[:,cropping1[i,0]:(-1*cropping1[i,1])],\n",
    "                               m2[:,cropping2[i,0]:(-1*cropping2[i,1])]), axis=1).T\n",
    "\n",
    "with h5py.File('preprocessed/movie.h5', 'w') as hf:\n",
    "    hf.create_dataset('D', data=D)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91516f80282b50a515a4cd2b84bb75d2e0ca1f48fcb38dd3f9e552eff8c6ac80"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('deepmreye')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
